[
    {
        "test_name": "llama70B_tp4_ms-8_cp-false_so-true_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 8,
            "multi_step_stream_outputs": "true"
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    },
    {
        "test_name": "llama70B_tp4_ms-16_cp-false_so-true_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 16,
            "multi_step_stream_outputs": "true"
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    },
    {
        "test_name": "llama70B_tp4_ms-8_cp-false_so-false_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 8,
            "multi_step_stream_outputs": "false"
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    },
    {
        "test_name": "llama70B_tp4_ms-16_cp-false_so-false_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 16,
            "multi_step_stream_outputs": "false"
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    },
    {
        "test_name": "llama70B_tp4_ms-8_cp-true_so-true_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 8,
            "multi_step_stream_outputs": "true",
            "enable_chunked_prefill" : ""
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    },
    {
        "test_name": "llama70B_tp4_ms-16_cp-true_so-true_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 16,
            "multi_step_stream_outputs": "true",
            "enable_chunked_prefill" : ""
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    },
    {
        "test_name": "llama70B_tp4_ms-8_cp-true_so-false_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 8,
            "multi_step_stream_outputs": "false",
            "enable_chunked_prefill" : ""
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    },
    {
        "test_name": "llama70B_tp4_ms-16_cp-true_so-false_sharegpt",
        "qps_list": [4,8,16,32,"inf"],
        "common_parameters": {
            "model": "/models/Meta-Llama-3-70B-Instruct",
            "tp": 4,
            "dataset_name": "sharegpt",
            "dataset_path": "./ShareGPT_V3_unfiltered_cleaned_split.json",
            "num_prompts": 500,
            "port": 8000,
            "reuse_server": false
        },
        "lmdeploy_server_parameters": {
            "dtype": "bfloat16"
        },
        "lmdeploy_client_parameters": {
        },
        "tgi_server_parameters": {
        },
        "tgi_client_parameters": {
            "endpoint": "/generate_stream"
        },
        "trt_server_parameters": {
            "model_type": "llama",
            "model_dtype": "bfloat16",
            "max_batch_size": 2048,
            "max_input_len": 4096,
            "max_seq_len": 6144,
            "max_num_tokens": 16384,
            "trt_llm_version": "v0.11.0"
        },
        "trt_client_parameters": {
            "endpoint": "/v2/models/ensemble/generate_stream"
        }, 
        "vllm_server_parameters": {
            "disable_log_stats": "",
            "disable_log_requests": "",
            "gpu_memory_utilization": 0.9410,
            "max_num_seqs": 512,
            "dtype": "bfloat16",
            "num_scheduler_steps": 16,
            "multi_step_stream_outputs": "false",
            "enable_chunked_prefill" : ""
        },
        "vllm_client_parameters": {
        },
        "sglang_server_parameters": {
            "disable_radix_cache": "",
            "enable_torch_compile": "",
            "dtype": "bfloat16"
        },
        "sglang_client_parameters": {
        }
    }


]
